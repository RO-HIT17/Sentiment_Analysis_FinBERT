{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yp995yDijhnzKGrQGLbgdArP7YEj_9IT",
      "authorship_tag": "ABX9TyP+TXRZ18DWvqD6V7oq/X4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RO-HIT17/Sentiment_Analysis_FinBERT/blob/main/BERT_sp_sv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ojsSXRbVMK9",
        "outputId": "3ae0855a-42a9-4b62-d94f-e8d63269cf43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from transformers.models.bert.modeling_bert import BertOnlyMLMHead\n",
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "from transformers.models.bert.modeling_bert import *"
      ],
      "metadata": {
        "id": "XFQkOho1Rv_H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "gKOgUcGxRz2U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModel_dropout(BertPreTrainedModel):\n",
        "    def __init__(self, config, add_pooling_layer=True):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "\n",
        "        self.pooler = BertPooler(config) if add_pooling_layer else None\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embeddings.word_embeddings\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embeddings.word_embeddings = value\n",
        "\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
        "        class PreTrainedModel\n",
        "        \"\"\"\n",
        "        for layer, heads in heads_to_prune.items():\n",
        "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        dropout_idx: Optional[int] = None,\n",
        "        vanilla_bert: Optional[bool] = False,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if self.config.is_decoder:\n",
        "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        else:\n",
        "            use_cache = False\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        batch_size, seq_length = input_shape\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
        "\n",
        "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
        "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
        "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
        "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
        "            if encoder_attention_mask is None:\n",
        "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
        "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
        "        else:\n",
        "            encoder_extended_attention_mask = None\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        # 1.0 in head_mask indicate we keep the head\n",
        "        # attention_probs has shape bsz x n_heads x N x N\n",
        "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
        "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length,\n",
        "        )\n",
        "\n",
        "        # dropout\n",
        "        if not vanilla_bert:\n",
        "\n",
        "            dropout_mask = torch.rand((embedding_output.size()[0], 1, embedding_output.size()[2]))\n",
        "            dropout_mask = torch.where(dropout_mask>0.3, torch.ones(dropout_mask.size()), torch.zeros(dropout_mask.size()))\n",
        "            left_ones = torch.ones((embedding_output.size()[0], dropout_idx, embedding_output.size()[2]))\n",
        "            right_ones = torch.ones((embedding_output.size()[0], embedding_output.size()[1]-dropout_idx-1, embedding_output.size()[2]))\n",
        "            dropout_mask_thistoken = torch.cat((left_ones, dropout_mask, right_ones), 1).cuda()\n",
        "            embedding_output = torch.mul(dropout_mask_thistoken, embedding_output)\n",
        "\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "\n",
        "        if not return_dict:\n",
        "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
        "\n",
        "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "            last_hidden_state=sequence_output,\n",
        "            pooler_output=pooled_output,\n",
        "            past_key_values=encoder_outputs.past_key_values,\n",
        "            hidden_states=encoder_outputs.hidden_states,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "            cross_attentions=encoder_outputs.cross_attentions,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "aUEe722ASnN_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMaskedLM_dropout(BertPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel_dropout(config, add_pooling_layer=False)\n",
        "        self.cls = BertOnlyMLMHead(config)\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "        self.sftmx = nn.Softmax(-1)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.cls.predictions.decoder\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.cls.predictions.decoder = new_embeddings\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
        "            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\n",
        "            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
        "        \"\"\"\n",
        "\n",
        "        ret = {}\n",
        "        sptopk = 50\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        for seq_idx in range(1, input_ids.shape[1]-1):\n",
        "\n",
        "            outputs = self.bert(\n",
        "                input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                position_ids=position_ids,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                encoder_hidden_states=encoder_hidden_states,\n",
        "                encoder_attention_mask=encoder_attention_mask,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "                dropout_idx=seq_idx\n",
        "            )\n",
        "\n",
        "            # s_p ------------------------------------------------------------------\n",
        "            # last hidden state output\n",
        "            prediction_scores = self.cls(outputs.last_hidden_state)\n",
        "            prediction_scores = self.sftmx(prediction_scores)\n",
        "            # propose 50 candidates using the approach in Section 2.1\n",
        "            prediction_top50 = torch.topk(prediction_scores, sptopk, dim=-1)\n",
        "            sp, prediction_top50_index = prediction_top50.values[0], prediction_top50.indices[0]\n",
        "            # predicted_token = [tokenizer.convert_ids_to_tokens(i) for i in prediction_top50_index]\n",
        "            # print(predicted_token)\n",
        "\n",
        "            # s_v ------------------------------------------------------------------\n",
        "            # original sentence embeddings\n",
        "            # use the concatenation of its representations in top four layers in BERT as its contextualized representation\n",
        "            last_four_layer_representation = torch.cat(outputs.hidden_states[-4:], dim = -1) # [1 * seq_len * 3072]\n",
        "\n",
        "            # w_{i,k} is the average self-attention score of all heads in all layers from i th token to k th position in x\n",
        "            avg_attn_score = torch.mean(torch.mean(torch.cat(outputs.attentions, dim=0), dim=0), dim=0) # [seq_len * seq_len]\n",
        "\n",
        "            input_ids_for_this_token = input_ids.repeat(sptopk, 1)\n",
        "            for j in range(sptopk):\n",
        "                input_ids_for_this_token[j][seq_idx] = prediction_top50_index[seq_idx][j]\n",
        "\n",
        "            outputs_for_this_token = self.bert(\n",
        "                input_ids_for_this_token,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                position_ids=position_ids,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                encoder_hidden_states=encoder_hidden_states,\n",
        "                encoder_attention_mask=encoder_attention_mask,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "                vanilla_bert=True\n",
        "            )\n",
        "\n",
        "            # s_v ------------------------------------------------------------------\n",
        "            # use the concatenation of its representations in top four layers in BERT as its contextualized representation\n",
        "            last_four_layer_representation_for_this_token = torch.cat(outputs_for_this_token.hidden_states[-4:], dim = -1) # [sptopk * seq_len * 3072]\n",
        "\n",
        "            cosine_similarities_for_this_token = self.cos(last_four_layer_representation, last_four_layer_representation_for_this_token) # [sptopk * seq_len]\n",
        "            sv = torch.mm(avg_attn_score[seq_idx:seq_idx+1, :], cosine_similarities_for_this_token.T) # [1, sptopk]\n",
        "\n",
        "            finalscore = sv + 0.01 * torch.log(sp[seq_idx:seq_idx+1, :]) # [1 * 50]\n",
        "            prediction_top10 = torch.topk(finalscore, 10, dim=-1)\n",
        "            predictions = torch.index_select(prediction_top50_index[seq_idx:seq_idx+1, :], 1, prediction_top10.indices[0])[0] # [1 * 10]\n",
        "            if predictions[0].item() != input_ids[0][seq_idx].item():\n",
        "                # prediction_logits = torch.index_select(finalscore, 1, prediction_top10.indices[0])[0] # [1 * 10]\n",
        "                prediction_tokens = tokenizer.convert_ids_to_tokens(predictions)\n",
        "                # print(tokenizer.convert_ids_to_tokens([input_ids[0][seq_idx].item()]))\n",
        "                # print(predicted_token[seq_idx:seq_idx+1])\n",
        "                # print(prediction_tokens)\n",
        "                # print(prediction_logits)\n",
        "                ret[tokenizer.convert_ids_to_tokens([input_ids[0][seq_idx].item()])[0]] = prediction_tokens\n",
        "\n",
        "        return ret\n"
      ],
      "metadata": {
        "id": "wL-QZMOtSqoW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(test_data='/content/drive/MyDrive/Data/SmartWordSuggestions/data/sws/sws_test.json'):\n",
        "    with open(test_data, 'r') as f:\n",
        "        js = json.load(f)\n",
        "\n",
        "    ret = {}\n",
        "\n",
        "    model = BertForMaskedLM_dropout.from_pretrained('bert-base-uncased')\n",
        "    model.cuda()\n",
        "\n",
        "    for sentidx, v in tqdm(js.items()):\n",
        "        sentence = v['sentence']\n",
        "        tokens = ['[CLS]'] + tokenizer.tokenize(sentence) + ['[SEP]']\n",
        "        masked_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tokens)]).cuda()\n",
        "        segment_ids = torch.tensor([[0] * len(tokens)]).cuda()\n",
        "        substitution_results = model(masked_ids, token_type_ids=segment_ids, output_hidden_states=True, return_dict=True, output_attentions=True)\n",
        "\n",
        "        res = []\n",
        "        for idx, token in enumerate(nltk.word_tokenize(sentence)):\n",
        "            tk = tokenizer.tokenize(token)[0]\n",
        "            if tk in substitution_results:\n",
        "                res.append([[token, idx, idx + 1], substitution_results[tk]])\n",
        "\n",
        "        ret[sentidx] = {'substitute_topk': res}\n",
        "\n",
        "    # Save the results\n",
        "    with open('res.json', 'w') as f:\n",
        "        json.dump(ret, f, indent=4)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    save_directory = \"./fine_tuned_bert\"\n",
        "    model.save_pretrained(save_directory, safe_serialization=False)\n",
        "    tokenizer.save_pretrained(save_directory)\n",
        "    print(f\"Model and tokenizer saved to {save_directory}\")\n",
        "\n",
        "# Run the evaluation and save model\n",
        "eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ioKCgnoR1fH",
        "outputId": "0f48caaf-e3df-44b8-f740-2ee04922639d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [54:45<00:00,  4.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./fine_tuned_bert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Rvtunu_3iI1q",
        "outputId": "69346da7-dc53-4340-fcdd-5e686e94e420"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a00976eaa033>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}